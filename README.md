# AnomaData - Predictive Maintenance & Anomaly Detection Dataset

## ğŸ“Œ Project Overview
The **AnomaData** dataset is designed for **predictive maintenance and anomaly detection** in industrial equipment.  
It contains **time-series sensor readings** with binary anomaly labels, helping identify patterns that lead to machine breakdowns.

---

## ğŸ“Š Dataset Attributes

| Column Name | Data Type | Description |
|-------------|------------|------------------------------------------------|
| **time** | `datetime` | The timestamp when the sensor data was recorded. |
| **y** | `int (0 or 1)` | The target variable: `0 = Normal`, `1 = Anomaly (Machine Failure)`. |
| **x1** - **x60** | `float` | Sensor readings capturing machine performance, vibration, temperature, and pressure. |

### **1ï¸âƒ£ Target Variable: `y`**
- `0` â†’ Normal operation  
- `1` â†’ Anomaly detected (machine failure or abnormal event)

### **2ï¸âƒ£ Time Column: `time`**
- The dataset spans **May 1999**.
- Captures machine behavior **over time** (time-series data).
- Useful for **trend analysis, rolling averages, and lag feature engineering**.

### **3ï¸âƒ£ Sensor Readings (`x1` to `x60`)**
- These columns represent **various sensor measurements**.
- Can include data like **temperature, pressure, motor speed, vibration levels, and humidity**.
- Each sensor may indicate signs of wear, overheating, or unexpected spikes that signal anomalies.

---

## ğŸ“Œ Dataset Summary Statistics

- **Total Records**: `~18,398`
- **Anomaly Rate**: `~0.67%` (`y=1` is rare)
- **Feature Count**: `60` sensor readings (`x1` - `x60`)
- **Time Period**: `May 1999`

---

## ğŸ—ï¸ Preprocessing Steps Applied
- **Converted `time` column to `datetime` format**.
- **Handled missing values** (using median imputation).
- **Standardized sensor readings** (MinMaxScaler).
- **Applied feature engineering** (lag features, rolling averages).
---
-- ** To successfully implement and evaluate One-Class SVM, Autoencoder, and Isolation Forest within a single script, careful structuring and variable management were essential. To maintain reproducibility and fairness in model evaluation, all key variables were reset before each model execution.  Final-report.pdf has all the details. 

## ğŸ” Modeling Approaches Used
### **1ï¸âƒ£ Isolation Forest (IF)**
- Strength: Good for **unsupervised anomaly detection**.
- Weakness: Performed poorly due to **low anomaly recall**.

### **2ï¸âƒ£ One-Class SVM**
- Strength: Learns from **only normal data (`y=0`)**.
- Weakness: **Recall was very low (4%)**, failing to detect most anomalies.

### **3ï¸âƒ£ Autoencoder (Best Performing)**
- Strength: **60% anomaly recall**, meaning it correctly detects more anomalies.
- Weakness: **Precision still low (8%)**, meaning too many false positives.

## ğŸ“‚ File Structure
AnomaData_Project
 â”œâ”€â”€ AnomaData.xlsx       # Original dataset
 â”œâ”€â”€ README.md           # Dataset documentation
 â”œâ”€â”€ Visuals        # visualizations - screenshots of visual charts - EDA and Results of each model.
 â”œâ”€â”€ notebooks       # Jupyter notebooks for EDA and training
	Main-script.py
 â”œâ”€â”€ models              # Serialized models and logs
	â”œâ”€â”€ autoencoder_model.h5  # Trained Autoencoder model
	â”œâ”€â”€ isolation_forest_model.pkl # Trained Isolation Forest model

 	â”œâ”€â”€ optimized_isolation_forest.pkl # Trained and optimized Isolation Forest model
â”œâ”€â”€ one_class_svm_model.pkl # Trained SVM Model

 â”œâ”€â”€ data                # Processed dataset versions
	â”œâ”€â”€ train_data.xlsx
	â”œâ”€â”€ test_data.xlsx
	â”œâ”€â”€ processed_data.xlsx
 â”œâ”€â”€ requirements.txt     # Python dependencies

## How to Run the Code (A file with all the dependencies - requirements.txt is attached to run the code) 
pip install pandas numpy matplotlib seaborn openpyxl scikit-learn
pip install tensorflow joblib
python notebooks/Main-script.py
